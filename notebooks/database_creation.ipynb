{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49574e4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33ce4be9-7b13-4155-b53a-2dc71b71e754",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\HP\\Documents\\Restaurent_database\\yelp_academic_dataset_business.json\"\n",
    "chunk_size = 5000\n",
    "chunks=[] \n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    batch = []\n",
    "    for i, line in enumerate(f):\n",
    "        batch.append(json.loads(line))\n",
    "        if (i+1) % chunk_size == 0:\n",
    "            chunk_df = pd.DataFrame(batch)\n",
    "            chunks.append(chunk_df)\n",
    "            batch = []\n",
    "    # last batch\n",
    "    if batch:\n",
    "        chunk_df = pd.DataFrame(batch)\n",
    "        chunks.append(chunk_df)\n",
    "\n",
    "business_df = pd.concat(chunks, ignore_index=True) \n",
    "# print(business_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e271d7a8-1284-442c-8b52-323bc184719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\HP\\Documents\\Restaurent_database\\yelp_academic_dataset_checkin.json\"\n",
    "chunk_size = 5000\n",
    "chunks=[] \n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    batch = []\n",
    "    for i, line in enumerate(f):\n",
    "        batch.append(json.loads(line))\n",
    "        if (i+1) % chunk_size == 0:\n",
    "            chunk_df = pd.DataFrame(batch)\n",
    "            chunks.append(chunk_df)\n",
    "            batch = []\n",
    "    # last batch\n",
    "    if batch:\n",
    "        chunk_df = pd.DataFrame(batch)\n",
    "        chunks.append(chunk_df)\n",
    "\n",
    "checkin_df = pd.concat(chunks, ignore_index=True) \n",
    "# print(checkin_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c8d9e63-afa4-415e-ace1-ba1d6d8e8565",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = r\"C:\\Users\\HP\\Documents\\Restaurent_database\\yelp_academic_dataset_review.json\"\n",
    "chunk_size = 20000\n",
    "chunks = []\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    batch = []\n",
    "    for i, line in enumerate(f):\n",
    "        batch.append(json.loads(line))\n",
    "        if (i+1) % chunk_size == 0:\n",
    "            chunk_df = pd.DataFrame(batch)\n",
    "            chunks.append(chunk_df)\n",
    "            batch = []\n",
    "    # last batch\n",
    "    if batch:\n",
    "        chunk_df = pd.DataFrame(batch)\n",
    "        chunks.append(chunk_df)\n",
    "\n",
    "review_df = pd.concat(chunks, ignore_index=True)\n",
    "# print(review_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "844be42b-27fb-48d0-9616-7a911e29a4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = r\"C:\\Users\\HP\\Documents\\Restaurent_database\\yelp_academic_dataset_tip.json\"\n",
    "chunk_size = 20000\n",
    "chunks = []\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    batch = []\n",
    "    for i, line in enumerate(f):\n",
    "        batch.append(json.loads(line))\n",
    "        if (i+1) % chunk_size == 0:\n",
    "            chunk_df = pd.DataFrame(batch)\n",
    "            chunks.append(chunk_df)\n",
    "            batch = []\n",
    "    # last batch\n",
    "    if batch:\n",
    "        chunk_df = pd.DataFrame(batch)\n",
    "        chunks.append(chunk_df)\n",
    "\n",
    "tip_df = pd.concat(chunks, ignore_index=True)\n",
    "# print(tip_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6c9b462-96f9-4876-838b-1d35076c064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = r\"C:\\Users\\HP\\Documents\\Restaurent_database\\yelp_academic_dataset_user.json\"\n",
    "chunk_size = 20000\n",
    "chunks = []\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    batch = []\n",
    "    for i, line in enumerate(f):\n",
    "        batch.append(json.loads(line))\n",
    "        if (i+1) % chunk_size == 0:\n",
    "            chunk_df = pd.DataFrame(batch)\n",
    "            chunks.append(chunk_df)\n",
    "            batch = []\n",
    "    # last batch\n",
    "    if batch:\n",
    "        chunk_df = pd.DataFrame(batch)\n",
    "        chunks.append(chunk_df)\n",
    "\n",
    "user_df = pd.concat(chunks, ignore_index=True)\n",
    "# print(user_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "019c3609-df4f-4cd0-a6ea-38a82f77921d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150346, 14)\n",
      "(131930, 2)\n",
      "(6990280, 9)\n",
      "(908915, 5)\n",
      "(1987897, 22)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes for verification\n",
    "print(business_df.shape)\n",
    "print(checkin_df.shape)\n",
    "print(review_df.shape)\n",
    "print(tip_df.shape)\n",
    "print(user_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "942ba823-d9bc-48a5-bdb2-c8faaad7a018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop specified columns from business_df\n",
    "business_df.drop(['attributes', 'hours'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbd99c27-7e51-4dac-89b5-520c85840e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create a SQLite engine\n",
    "engine = create_engine('sqlite:///yelp.db')\n",
    "\n",
    "# Define function to load DataFrame into a SQL table with chunksize\n",
    "def load_dataframe(df, table_name, engine, chunksize=5000):\n",
    "    df.to_sql(table_name, con=engine, if_exists='replace', index=False, chunksize=chunksize)\n",
    "\n",
    "\n",
    "# Load each DataFrame into a separate table using chunking for large DataFrames\n",
    "load_dataframe(business_df, 'business', engine , chunksize=5000)\n",
    "load_dataframe(review_df, 'review', engine, chunksize=5000)  # Large file uses chunksize\n",
    "load_dataframe(user_df, 'user', engine , chunksize=5000)\n",
    "load_dataframe(tip_df, 'tip', engine , chunksize=5000)\n",
    "load_dataframe(checkin_df, 'checkin', engine , chunksize=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a117a-0234-4e68-b700-6f6243e9d9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
